{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7263f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26cfd57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imread, imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49bf10d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "from keras.models import model_from_json\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Loading the model\n",
    "json_file = open('model_final.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"model_final.h5\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a634dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model weights from a file\n",
    "loaded_model.load_weights(\"model_final.h5\")\n",
    "\n",
    "# Loading a test image\n",
    "img_path = '/Users/alyona_dushkina/1.jpg'\n",
    "img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "img = img.resize((28, 28))  # Resize image to 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "617587a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting an image to a numpy array\n",
    "x = np.array(img)\n",
    "x = x.reshape(1, 1, 28, 28)  # Reshaping an Array to Fit Model Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcd88eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 116ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 18:33:47.387941: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# Making a prediction using a loaded model\n",
    "predictions = loaded_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1353563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determination of the class with the highest probability\n",
    "predicted_class_index = np.argmax(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a302fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Definition of a classified result\n",
    "if predicted_class_index == 10:\n",
    "    print('-')\n",
    "elif predicted_class_index == 11:\n",
    "    print('+')\n",
    "elif predicted_class_index == 12:\n",
    "    print('/')\n",
    "elif predicted_class_index == 13:\n",
    "    print('=')\n",
    "else:\n",
    "    print(predicted_class_index)  # Class index output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62955278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('/Users/alyona_dushkina/Desktop/3+4_.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if img is not None and img.shape[0] > 0 and img.shape[1] > 0:\n",
    "    img = ~img\n",
    "    ret, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnt = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "    w, h = int(28), int(28)\n",
    "    train_data = []\n",
    "\n",
    "    rects = []\n",
    "    for c in cnt:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        rect = [x, y, w, h]\n",
    "        rects.append(rect)\n",
    "\n",
    "    bool_rect = []\n",
    "    for r in rects:\n",
    "        l = []\n",
    "        for rec in rects:\n",
    "            flag = 0\n",
    "            if rec != r:\n",
    "                if r[0] < (rec[0] + rec[2] + 10) and rec[0] < (r[0] + r[2] + 10) and r[1] < (rec[1] + rec[3] + 10) and rec[1] < (r[1] + r[3] + 10):\n",
    "                    flag = 1\n",
    "                l.append(flag)\n",
    "            if rec == r:\n",
    "                l.append(0)\n",
    "        bool_rect.append(l)\n",
    "\n",
    "    dump_rect = []\n",
    "    for i in range(0, len(cnt)):\n",
    "        for j in range(0, len(cnt)):\n",
    "            if bool_rect[i][j] == 1:\n",
    "                area1 = rects[i][2] * rects[i][3]\n",
    "                area2 = rects[j][2] * rects[j][3]\n",
    "                if(area1 == min(area1, area2)):\n",
    "                    dump_rect.append(rects[i])\n",
    "\n",
    "    final_rect = [i for i in rects if i not in dump_rect]\n",
    "\n",
    "    for r in final_rect:\n",
    "        x, y, w, h = r[0], r[1], r[2], r[3]\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        resized_roi = cv2.resize(roi, (28, 28))\n",
    "        train_data.append(resized_roi)\n",
    "\n",
    "    # Displaying images from train_data\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(len(train_data)):\n",
    "        plt.subplot(1, len(train_data), i+1)\n",
    "        plt.imshow(train_data[i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dddccb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "3+4\n"
     ]
    }
   ],
   "source": [
    "s = ''\n",
    "for roi in train_data:\n",
    "    roi = np.expand_dims(roi, axis=0)  \n",
    "    roi = np.expand_dims(roi, axis=0)  \n",
    "    result = loaded_model.predict(roi)\n",
    "    predicted_class_index = np.argmax(result)\n",
    "    \n",
    "    if predicted_class_index == 10:\n",
    "        s += '-'\n",
    "    elif predicted_class_index == 11:\n",
    "        s += '+'\n",
    "    elif predicted_class_index == 12:\n",
    "        s += '/'\n",
    "    elif predicted_class_index == 13:\n",
    "        s += '='\n",
    "    else:\n",
    "        s += str(predicted_class_index)\n",
    "\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ed8a645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
